#!/usr/bin/env python3
"""
æ·±åº¦æ€§èƒ½åˆ†æ - æ‰¾å‡ºçœŸæ­£çš„ç“¶é¢ˆ
Deep Performance Analysis - Find Real Bottlenecks
"""

import time
import json
import sys
import os
from typing import Dict, List, Any
import tracemalloc
import psutil
import threading
from concurrent.futures import ThreadPoolExecutor
import asyncio

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

def analyze_llm_call_performance():
    """åˆ†æLLMè°ƒç”¨æ€§èƒ½"""
    print("ğŸ” åˆ†æLLMè°ƒç”¨æ€§èƒ½...")
    
    # å¯¼å…¥LLMæ¨¡å—
    try:
        from core.llm import llm_callable
        print("âœ… æˆåŠŸå¯¼å…¥LLMæ¨¡å—")
    except Exception as e:
        print(f"âŒ å¯¼å…¥LLMæ¨¡å—å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•LLMè°ƒç”¨æ€§èƒ½
    test_prompts = [
        "Calculate 1 + 1",
        "Count words in: 'Hello world'",
        "Sum of [1, 2, 3]",
        "Choose larger: 5 or 10"
    ]
    
    print("\nğŸ“Š LLMè°ƒç”¨æ€§èƒ½æµ‹è¯•:")
    
    for i, prompt in enumerate(test_prompts):
        start_time = time.time()
        try:
            result = llm_callable(prompt, "default")
            end_time = time.time()
            execution_time = end_time - start_time
            print(f"   æµ‹è¯• {i+1}: {execution_time*1000:.2f}ms - {prompt[:20]}...")
        except Exception as e:
            print(f"   æµ‹è¯• {i+1}: å¤±è´¥ - {e}")

def analyze_framework_overhead():
    """åˆ†ææ¡†æ¶å¼€é”€"""
    print("\nğŸ” åˆ†ææ¡†æ¶å¼€é”€...")
    
    # æµ‹è¯•ç›´æ¥æ‰§è¡Œ
    def direct_execution():
        """ç›´æ¥æ‰§è¡Œä»»åŠ¡"""
        start_time = time.time()
        # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
        result = "Task completed"
        end_time = time.time()
        return end_time - start_time
    
    # æµ‹è¯•DSLæ‰§è¡Œ
    def dsl_execution():
        """é€šè¿‡DSLæ‰§è¡Œä»»åŠ¡"""
        try:
            from dsl.fast_dsl import FastDSL
            from core.llm import llm_callable
            
            dsl = FastDSL(workers=1)
            dsl.use_llm(llm_callable)
            
            start_time = time.time()
            task = dsl.task("test", prompt="Calculate 1 + 1", agent="default")
            scheduled_task = task.schedule()
            result = scheduled_task.wait(timeout=5)
            end_time = time.time()
            
            dsl.shutdown()
            return end_time - start_time
        except Exception as e:
            print(f"DSLæ‰§è¡Œå¤±è´¥: {e}")
            return None
    
    # æµ‹è¯•å…¶ä»–æ¡†æ¶
    def langchain_execution():
        """LangChainæ‰§è¡Œ"""
        try:
            from langchain.agents import initialize_agent, AgentType
            from langchain.tools import Tool
            from langchain_openai import ChatOpenAI
            
            llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0, timeout=30)
            
            def simple_tool(input_text: str) -> str:
                return "Task completed"
            
            tools = [Tool(name="simple_tool", func=simple_tool, description="Simple tool")]
            agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False)
            
            start_time = time.time()
            result = agent.run("Calculate 1 + 1")
            end_time = time.time()
            
            return end_time - start_time
        except Exception as e:
            print(f"LangChainæ‰§è¡Œå¤±è´¥: {e}")
            return None
    
    # è¿è¡Œæµ‹è¯•
    print("\nğŸ“Š æ¡†æ¶å¼€é”€æµ‹è¯•:")
    
    # ç›´æ¥æ‰§è¡Œ
    direct_time = direct_execution()
    print(f"   ç›´æ¥æ‰§è¡Œ: {direct_time*1000:.2f}ms")
    
    # DSLæ‰§è¡Œ
    dsl_time = dsl_execution()
    if dsl_time:
        print(f"   DSLæ‰§è¡Œ: {dsl_time*1000:.2f}ms")
        print(f"   DSLå¼€é”€: {(dsl_time - direct_time)*1000:.2f}ms")
    
    # LangChainæ‰§è¡Œ
    langchain_time = langchain_execution()
    if langchain_time:
        print(f"   LangChainæ‰§è¡Œ: {langchain_time*1000:.2f}ms")
        print(f"   LangChainå¼€é”€: {(langchain_time - direct_time)*1000:.2f}ms")

def analyze_memory_usage():
    """åˆ†æå†…å­˜ä½¿ç”¨"""
    print("\nğŸ” åˆ†æå†…å­˜ä½¿ç”¨...")
    
    process = psutil.Process()
    
    # æµ‹è¯•ä¸åŒæ¡†æ¶çš„å†…å­˜ä½¿ç”¨
    frameworks = {
        "Direct": lambda: "Task completed",
        "DSL": lambda: exec_dsl_task(),
        "LangChain": lambda: exec_langchain_task()
    }
    
    def exec_dsl_task():
        try:
            from dsl.fast_dsl import FastDSL
            from core.llm import llm_callable
            
            dsl = FastDSL(workers=1)
            dsl.use_llm(llm_callable)
            task = dsl.task("test", prompt="Calculate 1 + 1", agent="default")
            scheduled_task = task.schedule()
            result = scheduled_task.wait(timeout=5)
            dsl.shutdown()
            return result
        except Exception as e:
            return f"Error: {e}"
    
    def exec_langchain_task():
        try:
            from langchain.agents import initialize_agent, AgentType
            from langchain.tools import Tool
            from langchain_openai import ChatOpenAI
            
            llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0, timeout=30)
            
            def simple_tool(input_text: str) -> str:
                return "Task completed"
            
            tools = [Tool(name="simple_tool", func=simple_tool, description="Simple tool")]
            agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False)
            
            result = agent.run("Calculate 1 + 1")
            return result
        except Exception as e:
            return f"Error: {e}"
    
    print("\nğŸ“Š å†…å­˜ä½¿ç”¨æµ‹è¯•:")
    
    for name, func in frameworks.items():
        initial_memory = process.memory_info().rss / 1024 / 1024
        
        try:
            result = func()
            final_memory = process.memory_info().rss / 1024 / 1024
            memory_delta = final_memory - initial_memory
            
            print(f"   {name}: {memory_delta:.2f} MB")
        except Exception as e:
            print(f"   {name}: å¤±è´¥ - {e}")

def analyze_concurrent_performance():
    """åˆ†æå¹¶å‘æ€§èƒ½"""
    print("\nğŸ” åˆ†æå¹¶å‘æ€§èƒ½...")
    
    def test_concurrent_execution(workers: int, tasks: int):
        """æµ‹è¯•å¹¶å‘æ‰§è¡Œ"""
        def worker_task():
            return "Task completed"
        
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = [executor.submit(worker_task) for _ in range(tasks)]
            results = [future.result() for future in futures]
        
        end_time = time.time()
        execution_time = end_time - start_time
        throughput = tasks / execution_time
        
        return execution_time, throughput
    
    print("\nğŸ“Š å¹¶å‘æ€§èƒ½æµ‹è¯•:")
    
    test_configs = [
        (1, 10),
        (5, 50),
        (10, 100)
    ]
    
    for workers, tasks in test_configs:
        execution_time, throughput = test_concurrent_execution(workers, tasks)
        print(f"   {workers} workers, {tasks} tasks: {execution_time*1000:.2f}ms, {throughput:.2f} tasks/sec")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ æ·±åº¦æ€§èƒ½åˆ†æå¼€å§‹")
    print("=" * 60)
    
    # åˆ†æLLMè°ƒç”¨æ€§èƒ½
    analyze_llm_call_performance()
    
    # åˆ†ææ¡†æ¶å¼€é”€
    analyze_framework_overhead()
    
    # åˆ†æå†…å­˜ä½¿ç”¨
    analyze_memory_usage()
    
    # åˆ†æå¹¶å‘æ€§èƒ½
    analyze_concurrent_performance()
    
    print("\n" + "=" * 60)
    print("âœ… æ·±åº¦æ€§èƒ½åˆ†æå®Œæˆ")

if __name__ == "__main__":
    main()
