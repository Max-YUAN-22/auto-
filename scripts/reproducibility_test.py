#!/usr/bin/env python3
"""
CCF Aç±»ä¼šè®®å®éªŒå¯å¤ç°æ€§éªŒè¯è„šæœ¬
CCF A-Class Conference Experiment Reproducibility Verification Script

è¿™ä¸ªè„šæœ¬ç¡®ä¿æ‰€æœ‰å®éªŒçš„å¯å¤ç°æ€§ï¼ŒåŒ…æ‹¬ï¼š
1. éšæœºç§å­è®¾ç½®
2. ç¯å¢ƒé…ç½®éªŒè¯
3. ä¾èµ–ç‰ˆæœ¬æ£€æŸ¥
4. APIé…ç½®éªŒè¯
5. å¤šæ¬¡è¿è¡Œç»“æœä¸€è‡´æ€§æ£€æŸ¥
"""

import os
import sys
import json
import time
import random
import numpy as np
import subprocess
import importlib
from typing import Dict, List, Any, Tuple
import logging
from pathlib import Path
import hashlib
import platform
import psutil

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ReproducibilityTest:
    """CCF Aç±»ä¼šè®®å®éªŒå¯å¤ç°æ€§éªŒè¯"""
    
    def __init__(self):
        self.results = {}
        self.test_runs = 3  # è¿è¡Œ3æ¬¡éªŒè¯ä¸€è‡´æ€§
        self.random_seed = 42  # å›ºå®šéšæœºç§å­
        self.tolerance = 0.1  # 10%çš„å®¹å·®
        
    def setup_reproducible_environment(self):
        """è®¾ç½®å¯å¤ç°çš„å®éªŒç¯å¢ƒ"""
        logger.info("ğŸ”§ è®¾ç½®å¯å¤ç°çš„å®éªŒç¯å¢ƒ...")
        
        # è®¾ç½®éšæœºç§å­
        random.seed(self.random_seed)
        np.random.seed(self.random_seed)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['PYTHONHASHSEED'] = str(self.random_seed)
        os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
        
        logger.info(f"âœ… éšæœºç§å­è®¾ç½®ä¸º: {self.random_seed}")
        
    def check_environment_consistency(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç¯å¢ƒä¸€è‡´æ€§"""
        logger.info("ğŸ” æ£€æŸ¥ç¯å¢ƒä¸€è‡´æ€§...")
        
        env_info = {
            "python_version": sys.version,
            "platform": platform.platform(),
            "cpu_count": psutil.cpu_count(),
            "memory_gb": psutil.virtual_memory().total / (1024**3),
            "python_hash_seed": os.environ.get('PYTHONHASHSEED'),
            "working_directory": os.getcwd(),
            "timestamp": time.time()
        }
        
        # æ£€æŸ¥å…³é”®ä¾èµ–ç‰ˆæœ¬
        dependencies = [
            'numpy', 'pandas', 'matplotlib', 'psutil',
            'langchain', 'openai', 'crewai', 'autogen'
        ]
        
        env_info["dependencies"] = {}
        for dep in dependencies:
            try:
                module = importlib.import_module(dep)
                version = getattr(module, '__version__', 'unknown')
                env_info["dependencies"][dep] = version
            except ImportError:
                env_info["dependencies"][dep] = "not_installed"
        
        logger.info("âœ… ç¯å¢ƒä¿¡æ¯æ”¶é›†å®Œæˆ")
        return env_info
        
    def verify_api_configuration(self) -> bool:
        """éªŒè¯APIé…ç½®"""
        logger.info("ğŸ”‘ éªŒè¯APIé…ç½®...")
        
        api_key = os.environ.get('OPENAI_API_KEY')
        api_base = os.environ.get('OPENAI_API_BASE', 'https://api.openai.com/v1')
        
        if not api_key:
            logger.error("âŒ OPENAI_API_KEY æœªè®¾ç½®")
            return False
            
        if not api_key.startswith('sk-'):
            logger.error("âŒ OPENAI_API_KEY æ ¼å¼ä¸æ­£ç¡®")
            return False
            
        logger.info(f"âœ… APIé…ç½®éªŒè¯é€šè¿‡")
        logger.info(f"   API Base: {api_base}")
        logger.info(f"   API Key: {api_key[:10]}...")
        
        return True
        
    def run_reproducibility_test(self, test_function, test_name: str) -> Dict[str, Any]:
        """è¿è¡Œå¯å¤ç°æ€§æµ‹è¯•"""
        logger.info(f"ğŸ§ª è¿è¡Œå¯å¤ç°æ€§æµ‹è¯•: {test_name}")
        
        results = []
        
        for run in range(self.test_runs):
            logger.info(f"   è¿è¡Œ {run + 1}/{self.test_runs}")
            
            # é‡ç½®éšæœºç§å­
            random.seed(self.random_seed)
            np.random.seed(self.random_seed)
            
            # è¿è¡Œæµ‹è¯•
            start_time = time.time()
            result = test_function()
            end_time = time.time()
            
            result["run_id"] = run + 1
            result["execution_time"] = end_time - start_time
            result["timestamp"] = time.time()
            
            results.append(result)
            
        # åˆ†æç»“æœä¸€è‡´æ€§
        consistency_analysis = self.analyze_consistency(results)
        
        return {
            "test_name": test_name,
            "runs": results,
            "consistency": consistency_analysis,
            "is_reproducible": consistency_analysis["is_consistent"]
        }
        
    def analyze_consistency(self, results: List[Dict]) -> Dict[str, Any]:
        """åˆ†æç»“æœä¸€è‡´æ€§"""
        if len(results) < 2:
            return {"is_consistent": True, "reason": "single_run"}
            
        # æå–å…³é”®æŒ‡æ ‡
        metrics = {}
        for result in results:
            for key, value in result.items():
                if isinstance(value, (int, float)) and key not in ["run_id", "execution_time", "timestamp"]:
                    if key not in metrics:
                        metrics[key] = []
                    metrics[key].append(value)
        
        consistency_report = {
            "is_consistent": True,
            "metrics_analysis": {},
            "failed_metrics": []
        }
        
        for metric_name, values in metrics.items():
            if len(values) < 2:
                continue
                
            mean_val = np.mean(values)
            std_val = np.std(values)
            cv = std_val / mean_val if mean_val != 0 else 0
            
            is_consistent = cv < self.tolerance
            
            consistency_report["metrics_analysis"][metric_name] = {
                "mean": mean_val,
                "std": std_val,
                "cv": cv,
                "is_consistent": is_consistent,
                "values": values
            }
            
            if not is_consistent:
                consistency_report["is_consistent"] = False
                consistency_report["failed_metrics"].append(metric_name)
        
        return consistency_report
        
    def test_our_dsl_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•Our DSLæ¡†æ¶æ€§èƒ½"""
        try:
            # å¯¼å…¥æˆ‘ä»¬çš„DSLæ¡†æ¶
            sys.path.append('.')
            from dsl.dsl import DSL
            from core.llm import llm_callable
            
            # åˆ›å»ºDSLå®ä¾‹
            dsl = DSL(workers=4)
            dsl.use_llm(llm_callable)
            
            # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
            tasks = []
            for i in range(10):
                task = dsl.task(f"test_task_{i}")
                tasks.append(task)
            
            # æ‰§è¡Œä»»åŠ¡
            start_time = time.time()
            results = []
            for task in tasks:
                result = dsl.run(task)
                results.append(result)
            end_time = time.time()
            
            return {
                "throughput": len(tasks) / (end_time - start_time),
                "latency": (end_time - start_time) / len(tasks),
                "success_rate": 1.0,
                "memory_usage": psutil.Process().memory_info().rss / 1024 / 1024,
                "task_count": len(tasks)
            }
            
        except Exception as e:
            logger.error(f"âŒ Our DSLæµ‹è¯•å¤±è´¥: {e}")
            return {
                "throughput": 0,
                "latency": 0,
                "success_rate": 0,
                "memory_usage": 0,
                "task_count": 0,
                "error": str(e)
            }
            
    def test_langchain_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•LangChainæ¡†æ¶æ€§èƒ½"""
        try:
            import langchain
            from langchain.llms import OpenAI
            from langchain.agents import initialize_agent, Tool
            from langchain.agents import AgentType
            
            # åˆ›å»ºLLM
            llm = OpenAI(temperature=0)
            
            # åˆ›å»ºç®€å•å·¥å…·
            def dummy_tool(query: str) -> str:
                return f"å¤„ç†æŸ¥è¯¢: {query}"
            
            tools = [Tool(name="dummy", func=dummy_tool, description="è™šæ‹Ÿå·¥å…·")]
            
            # åˆ›å»ºä»£ç†
            agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False)
            
            # æ‰§è¡Œæµ‹è¯•ä»»åŠ¡
            start_time = time.time()
            results = []
            for i in range(5):  # å‡å°‘ä»»åŠ¡æ•°é‡ä»¥æé«˜ç¨³å®šæ€§
                try:
                    result = agent.run(f"æµ‹è¯•ä»»åŠ¡ {i}")
                    results.append(result)
                except Exception as e:
                    logger.warning(f"LangChainä»»åŠ¡ {i} å¤±è´¥: {e}")
            end_time = time.time()
            
            return {
                "throughput": len(results) / (end_time - start_time) if end_time > start_time else 0,
                "latency": (end_time - start_time) / len(results) if results else 0,
                "success_rate": len(results) / 5,
                "memory_usage": psutil.Process().memory_info().rss / 1024 / 1024,
                "task_count": len(results)
            }
            
        except Exception as e:
            logger.error(f"âŒ LangChainæµ‹è¯•å¤±è´¥: {e}")
            return {
                "throughput": 0,
                "latency": 0,
                "success_rate": 0,
                "memory_usage": 0,
                "task_count": 0,
                "error": str(e)
            }
            
    def generate_reproducibility_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆå¯å¤ç°æ€§æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆå¯å¤ç°æ€§æŠ¥å‘Š...")
        
        # ç¯å¢ƒä¿¡æ¯
        env_info = self.check_environment_consistency()
        
        # APIé…ç½®éªŒè¯
        api_valid = self.verify_api_configuration()
        
        # è¿è¡Œå¯å¤ç°æ€§æµ‹è¯•
        our_dsl_test = self.run_reproducibility_test(self.test_our_dsl_performance, "Our DSL Framework")
        langchain_test = self.run_reproducibility_test(self.test_langchain_performance, "LangChain Framework")
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            "timestamp": time.time(),
            "random_seed": self.random_seed,
            "test_runs": self.test_runs,
            "tolerance": self.tolerance,
            "environment": env_info,
            "api_configuration_valid": api_valid,
            "tests": {
                "our_dsl": our_dsl_test,
                "langchain": langchain_test
            },
            "overall_reproducibility": {
                "our_dsl_reproducible": our_dsl_test["is_reproducible"],
                "langchain_reproducible": langchain_test["is_reproducible"],
                "overall_score": "high" if (our_dsl_test["is_reproducible"] and langchain_test["is_reproducible"]) else "medium"
            }
        }
        
        return report
        
    def save_report(self, report: Dict[str, Any], filename: str = "reproducibility_report.json"):
        """ä¿å­˜å¯å¤ç°æ€§æŠ¥å‘Š"""
        output_path = Path("results") / filename
        output_path.parent.mkdir(exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        logger.info(f"ğŸ“„ å¯å¤ç°æ€§æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        
    def run_full_reproducibility_test(self):
        """è¿è¡Œå®Œæ•´çš„å¯å¤ç°æ€§æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹CCF Aç±»ä¼šè®®å®éªŒå¯å¤ç°æ€§éªŒè¯")
        logger.info("=" * 60)
        
        # è®¾ç½®å¯å¤ç°ç¯å¢ƒ
        self.setup_reproducible_environment()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_reproducibility_report()
        
        # ä¿å­˜æŠ¥å‘Š
        self.save_report(report)
        
        # æ‰“å°æ‘˜è¦
        logger.info("ğŸ“‹ å¯å¤ç°æ€§æµ‹è¯•æ‘˜è¦:")
        logger.info(f"   Our DSLæ¡†æ¶å¯å¤ç°æ€§: {'âœ… é€šè¿‡' if report['tests']['our_dsl']['is_reproducible'] else 'âŒ å¤±è´¥'}")
        logger.info(f"   LangChainæ¡†æ¶å¯å¤ç°æ€§: {'âœ… é€šè¿‡' if report['tests']['langchain']['is_reproducible'] else 'âŒ å¤±è´¥'}")
        logger.info(f"   æ€»ä½“å¯å¤ç°æ€§è¯„åˆ†: {report['overall_reproducibility']['overall_score']}")
        
        return report

def main():
    """ä¸»å‡½æ•°"""
    test = ReproducibilityTest()
    report = test.run_full_reproducibility_test()
    
    # æ£€æŸ¥æ˜¯å¦é€šè¿‡
    if report['overall_reproducibility']['overall_score'] == 'high':
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å®éªŒå…·æœ‰è‰¯å¥½çš„å¯å¤ç°æ€§ã€‚")
        sys.exit(0)
    else:
        logger.warning("âš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")
        sys.exit(1)

if __name__ == "__main__":
    main()


