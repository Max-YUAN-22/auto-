#!/usr/bin/env python3
"""
æ¶ˆèå®éªŒæ¡†æ¶ - å®Œå…¨çœŸå®çš„APIè°ƒç”¨å®éªŒ
Ablation Study Framework - Fully Real API Call Experiments

åˆ†æOur DSLæ¡†æ¶å„ä¸ªç»„ä»¶çš„è´¡çŒ®ï¼š
1. ç¼“å­˜æœºåˆ¶çš„å½±å“
2. è°ƒåº¦ç­–ç•¥çš„å½±å“  
3. è´Ÿè½½å‡è¡¡çš„å½±å“
4. é‡è¯•æœºåˆ¶çš„å½±å“
5. å†…å­˜ä¼˜åŒ–çš„å½±å“
"""

import os
import sys
import json
import time
import logging
import numpy as np
import psutil
import gc
from datetime import datetime
from typing import Dict, List, Any, Tuple
from contextlib import contextmanager

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.join(os.path.dirname(__file__), '..')
sys.path.insert(0, project_root)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AblationStudy:
    """æ¶ˆèå®éªŒç±»"""
    
    def __init__(self, random_seed: int = 42):
        self.random_seed = random_seed
        np.random.seed(random_seed)
        
        # åŠ è½½ç¯å¢ƒå˜é‡
        self.load_env()
        
        # è®¾ç½®APIé…ç½®
        self.api_key = os.getenv("OPENAI_API_KEY", "sk-0WQRDm5w3t3ukRFQ7j33rOUgLk9ezcTuwhsK7BXxgfyhYuqA").strip()
        self.base_url = "https://www.yunqiaoai.top/v1"
        
        # å†…å­˜è·Ÿè¸ªå™¨
        self.memory_tracker = {}
        
        # æ¶ˆèå®éªŒé…ç½®
        self.ablation_config = {
            "scenarios": ["business_analysis", "technical_design", "scientific_research"],
            "agent_counts": [1, 2, 3, 4, 5],
            "complexities": ["simple", "medium", "complex"],
            "repetitions": 3,
            "ablation_components": [
                "baseline",           # åŸºçº¿ç‰ˆæœ¬ï¼ˆå®Œæ•´åŠŸèƒ½ï¼‰
                "no_cache",          # æ— ç¼“å­˜
                "no_scheduler",      # æ— æ™ºèƒ½è°ƒåº¦
                "no_load_balance",   # æ— è´Ÿè½½å‡è¡¡
                "no_retry",          # æ— é‡è¯•æœºåˆ¶
                "no_memory_opt"      # æ— å†…å­˜ä¼˜åŒ–
            ]
        }
        
        # æµ‹è¯•ä»»åŠ¡
        self.tasks = self._generate_ablation_tasks()
        
        logger.info(f"æ¶ˆèå®éªŒåˆå§‹åŒ–å®Œæˆ - ç»„ä»¶æ•°: {len(self.ablation_config['ablation_components'])}, "
                   f"åœºæ™¯æ•°: {len(self.ablation_config['scenarios'])}, "
                   f"ä»£ç†æ•°é‡: {len(self.ablation_config['agent_counts'])}")
    
    def load_env(self):
        """åŠ è½½ç¯å¢ƒå˜é‡"""
        os.environ['OPENAI_API_KEY'] = 'sk-0WQRDm5w3t3ukRFQ7j33rOUgLk9ezcTuwhsK7BXxgfyhYuqA'
        logger.info("è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
    
    def _generate_ablation_tasks(self) -> Dict[str, Dict[str, List[str]]]:
        """ç”Ÿæˆæ¶ˆèå®éªŒæµ‹è¯•ä»»åŠ¡"""
        tasks = {}
        
        # å•†ä¸šåˆ†æåœºæ™¯
        tasks["business_analysis"] = {
            "simple": [
                "åˆ†æä¸€å®¶å°å‹å’–å•¡åº—çš„æœˆåº¦é”€å”®æ•°æ®ï¼Œè¯†åˆ«é”€å”®è¶‹åŠ¿å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚",
                "è¯„ä¼°ä¸€ä¸ªåœ¨çº¿æ•™è‚²å¹³å°çš„ç”¨æˆ·å¢é•¿ç­–ç•¥ï¼Œæå‡ºä¼˜åŒ–æ–¹æ¡ˆã€‚"
            ],
            "medium": [
                "ä¸ºä¸€å®¶ä¸­å‹åˆ¶é€ ä¼ä¸šè®¾è®¡æ•°å­—åŒ–è½¬å‹è·¯çº¿å›¾ï¼ŒåŒ…æ‹¬æŠ€æœ¯é€‰å‹ã€å®æ–½è®¡åˆ’å’Œé£é™©è¯„ä¼°ã€‚",
                "åˆ†æç”µå•†å¹³å°çš„ä¾›åº”é“¾ç®¡ç†é—®é¢˜ï¼Œè®¾è®¡ä¼˜åŒ–æ–¹æ¡ˆä»¥æé«˜æ•ˆç‡å’Œé™ä½æˆæœ¬ã€‚"
            ],
            "complex": [
                "è®¾è®¡ä¸€ä¸ªå¤šå›½ä¼ä¸šçš„å…¨çƒä¾›åº”é“¾é£é™©ç®¡ç†æ¡†æ¶ï¼Œè€ƒè™‘åœ°ç¼˜æ”¿æ²»ã€è‡ªç„¶ç¾å®³ã€å¸‚åœºæ³¢åŠ¨ç­‰å› ç´ ï¼Œå¹¶æä¾›å®æ—¶ç›‘æ§å’Œåº”æ€¥å“åº”æœºåˆ¶ã€‚",
                "ä¸ºä¸€å®¶å¤§å‹é‡‘èæœºæ„è®¾è®¡åŸºäºAIçš„æ™ºèƒ½æŠ•é¡¾ç³»ç»Ÿæ¶æ„ï¼ŒåŒ…æ‹¬å®¢æˆ·ç”»åƒã€é£é™©è¯„ä¼°ã€æŠ•èµ„ç»„åˆä¼˜åŒ–å’Œåˆè§„ç®¡ç†ã€‚"
            ]
        }
        
        # æŠ€æœ¯è®¾è®¡åœºæ™¯
        tasks["technical_design"] = {
            "simple": [
                "è®¾è®¡ä¸€ä¸ªç®€å•çš„RESTful APIæ¶æ„ï¼ŒåŒ…æ‹¬è®¤è¯ã€æˆæƒå’Œæ•°æ®éªŒè¯æœºåˆ¶ã€‚",
                "ä¸ºç§»åŠ¨åº”ç”¨è®¾è®¡ç”¨æˆ·è®¤è¯å’Œä¼šè¯ç®¡ç†ç³»ç»Ÿã€‚"
            ],
            "medium": [
                "è®¾è®¡ä¸€ä¸ªå¾®æœåŠ¡æ¶æ„çš„ç”µå•†å¹³å°ï¼ŒåŒ…æ‹¬ç”¨æˆ·æœåŠ¡ã€å•†å“æœåŠ¡ã€è®¢å•æœåŠ¡å’Œæ”¯ä»˜æœåŠ¡ï¼Œè€ƒè™‘æœåŠ¡é—´é€šä¿¡ã€æ•°æ®ä¸€è‡´æ€§å’Œå®¹é”™æœºåˆ¶ã€‚",
                "è®¾è®¡ä¸€ä¸ªåˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿï¼Œæ”¯æŒé«˜å¹¶å‘è¯»å†™ã€æ•°æ®ä¸€è‡´æ€§å’Œæ•…éšœæ¢å¤ã€‚"
            ],
            "complex": [
                "è®¾è®¡ä¸€ä¸ªæ”¯æŒåƒä¸‡çº§ç”¨æˆ·çš„å®æ—¶æ¨èç³»ç»Ÿæ¶æ„ï¼ŒåŒ…æ‹¬æ•°æ®æ”¶é›†ã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒã€åœ¨çº¿æ¨ç†å’ŒA/Bæµ‹è¯•æ¡†æ¶ï¼Œè€ƒè™‘å»¶è¿Ÿã€å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§ã€‚",
                "è®¾è®¡ä¸€ä¸ªå¤šäº‘ç¯å¢ƒä¸‹çš„å®¹å™¨ç¼–æ’å¹³å°ï¼Œæ”¯æŒè‡ªåŠ¨æ‰©ç¼©å®¹ã€æœåŠ¡å‘ç°ã€è´Ÿè½½å‡è¡¡ã€ç›‘æ§å‘Šè­¦å’Œç¾éš¾æ¢å¤ã€‚"
            ]
        }
        
        # ç§‘å­¦ç ”ç©¶åœºæ™¯
        tasks["scientific_research"] = {
            "simple": [
                "åˆ†ææ°”å€™å˜åŒ–å¯¹å†œä¸šäº§é‡çš„å½±å“ï¼ŒåŸºäºå†å²æ•°æ®å»ºç«‹é¢„æµ‹æ¨¡å‹ã€‚",
                "ç ”ç©¶ç¤¾äº¤åª’ä½“å¯¹é’å°‘å¹´å¿ƒç†å¥åº·çš„å½±å“ï¼Œè®¾è®¡å®éªŒæ–¹æ¡ˆã€‚"
            ],
            "medium": [
                "è®¾è®¡ä¸€ä¸ªåŸºäºæœºå™¨å­¦ä¹ çš„è¯ç‰©å‘ç°å¹³å°ï¼ŒåŒ…æ‹¬åˆ†å­ç­›é€‰ã€æ´»æ€§é¢„æµ‹å’Œæ¯’æ€§è¯„ä¼°ï¼Œè€ƒè™‘æ•°æ®è´¨é‡å’Œæ¨¡å‹å¯è§£é‡Šæ€§ã€‚",
                "ç ”ç©¶é‡å­è®¡ç®—åœ¨å¯†ç å­¦ä¸­çš„åº”ç”¨ï¼Œåˆ†æé‡å­ç®—æ³•å¯¹ç°æœ‰åŠ å¯†ç³»ç»Ÿçš„å½±å“å¹¶æå‡ºåé‡å­å¯†ç å­¦æ–¹æ¡ˆã€‚"
            ],
            "complex": [
                "è®¾è®¡ä¸€ä¸ªå¤šæ¨¡æ€AIç³»ç»Ÿç”¨äºç™Œç—‡æ—©æœŸè¯Šæ–­ï¼Œæ•´åˆå½±åƒå­¦ã€åŸºå› ç»„å­¦ã€è›‹ç™½è´¨ç»„å­¦å’Œä¸´åºŠæ•°æ®ï¼Œå»ºç«‹ç«¯åˆ°ç«¯çš„è¯Šæ–­å’Œé¢„åé¢„æµ‹æ¨¡å‹ã€‚",
                "ç ”ç©¶å¯æ§æ ¸èšå˜ååº”å †çš„ç­‰ç¦»å­ä½“æ§åˆ¶ç®—æ³•ï¼Œè®¾è®¡å®æ—¶æ§åˆ¶ç³»ç»Ÿä»¥ç»´æŒç­‰ç¦»å­ä½“ç¨³å®šæ€§å’Œä¼˜åŒ–èƒ½é‡è¾“å‡ºã€‚"
            ]
        }
        
        return tasks
    
    @contextmanager
    def memory_tracking(self, component: str, scenario: str, agent_count: int, complexity: str):
        """å†…å­˜è·Ÿè¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        class MemoryTracker:
            def __init__(self, parent, component, scenario, agent_count, complexity):
                self.parent = parent
                self.component = component
                self.scenario = scenario
                self.agent_count = agent_count
                self.complexity = complexity
                self.initial_memory = None
                
            def __enter__(self):
                gc.collect()
                process = psutil.Process()
                self.initial_memory = process.memory_info().rss / 1024 / 1024  # MB
                return self
                
            def __exit__(self, exc_type, exc_val, exc_tb):
                process = psutil.Process()
                final_memory = process.memory_info().rss / 1024 / 1024  # MB
                memory_usage = max(0, final_memory - self.initial_memory)
                
                key = f"{self.component}_{self.scenario}_{self.agent_count}_{self.complexity}"
                self.parent.memory_tracker[key] = memory_usage
                logger.info(f"å†…å­˜ä½¿ç”¨è®°å½•: {key} = {memory_usage:.2f} MB")
        
        tracker = MemoryTracker(self, component, scenario, agent_count, complexity)
        try:
            yield tracker
        finally:
            pass
    
    def test_dsl_component(self, component: str, scenario: str, agent_count: int, complexity: str) -> Dict[str, Any]:
        """æµ‹è¯•DSLç‰¹å®šç»„ä»¶"""
        try:
            from dsl.dsl import DSL
            from core.robust_llm import llm_callable
            
            tasks = self.tasks[scenario][complexity]
            
            with self.memory_tracking(component, scenario, agent_count, complexity):
                start_time = time.time()
                
                # æ ¹æ®ç»„ä»¶ç±»å‹åˆ›å»ºä¸åŒçš„DSLé…ç½®
                if component == "baseline":
                    # åŸºçº¿ç‰ˆæœ¬ - å®Œæ•´åŠŸèƒ½
                    dsl = DSL(seed=self.random_seed, workers=min(agent_count, 8))
                elif component == "no_cache":
                    # æ— ç¼“å­˜ç‰ˆæœ¬
                    dsl = DSL(seed=self.random_seed, workers=min(agent_count, 8), enable_cache=False)
                elif component == "no_scheduler":
                    # æ— æ™ºèƒ½è°ƒåº¦ç‰ˆæœ¬
                    dsl = DSL(seed=self.random_seed, workers=min(agent_count, 8), enable_scheduler=False)
                elif component == "no_load_balance":
                    # æ— è´Ÿè½½å‡è¡¡ç‰ˆæœ¬
                    dsl = DSL(seed=self.random_seed, workers=min(agent_count, 8), enable_load_balance=False)
                elif component == "no_retry":
                    # æ— é‡è¯•æœºåˆ¶ç‰ˆæœ¬
                    dsl = DSL(seed=self.random_seed, workers=min(agent_count, 8), enable_retry=False)
                elif component == "no_memory_opt":
                    # æ— å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
                    dsl = DSL(seed=self.random_seed, workers=min(agent_count, 8), enable_memory_opt=False)
                else:
                    # é»˜è®¤åŸºçº¿ç‰ˆæœ¬
                    dsl = DSL(seed=self.random_seed, workers=min(agent_count, 8))
                
                # æ·»åŠ ä»»åŠ¡
                task_objects = []
                for i, task_prompt in enumerate(tasks[:agent_count]):
                    task_obj = dsl.gen(f"task_{i}", prompt=task_prompt, agent=f"agent_{i}").schedule()
                    task_objects.append(task_obj)
                
                # è¿è¡ŒDSL
                dsl.run(llm_callable)
                
                # ç­‰å¾…ä»»åŠ¡å®Œæˆ
                successful_tasks = 0
                for task in task_objects:
                    try:
                        result = task.wait(timeout=120.0)
                        if result is not None and len(str(result).strip()) > 100:
                            successful_tasks += 1
                    except Exception as e:
                        logger.warning(f"ä»»åŠ¡ç­‰å¾…å¤±è´¥: {e}")
                
                execution_time = time.time() - start_time
                throughput = successful_tasks / execution_time if execution_time > 0 else 0
                avg_latency = execution_time / successful_tasks if successful_tasks > 0 else 0
                success_rate = (successful_tasks / len(tasks[:agent_count])) * 100
                
            # åœ¨withè¯­å¥ç»“æŸåè·å–å†…å­˜ä½¿ç”¨
            memory_usage = self.memory_tracker.get(f"{component}_{scenario}_{agent_count}_{complexity}", 0)
            
            return {
                "component": component,
                "scenario": scenario,
                "agent_count": agent_count,
                "complexity": complexity,
                "execution_time": execution_time,
                "throughput": throughput,
                "success_rate": success_rate,
                "successful_tasks": successful_tasks,
                "total_tasks": len(tasks[:agent_count]),
                "avg_latency": avg_latency * 1000,  # è½¬æ¢ä¸ºms
                "status": "success",
                "memory_usage": memory_usage,
                "api_type": "real_api"
            }
                
        except Exception as e:
            logger.error(f"DSLç»„ä»¶æµ‹è¯•å¤±è´¥ ({component}): {e}")
            return {
                "component": component,
                "scenario": scenario,
                "agent_count": agent_count,
                "complexity": complexity,
                "execution_time": 0,
                "throughput": 0,
                "success_rate": 0,
                "successful_tasks": 0,
                "total_tasks": len(self.tasks[scenario][complexity][:agent_count]),
                "avg_latency": 0,
                "status": "error",
                "memory_usage": 0,
                "error": str(e),
                "api_type": "error"
            }
    
    def run_ablation_study(self) -> Dict[str, Any]:
        """è¿è¡Œæ¶ˆèå®éªŒ"""
        logger.info("ğŸ”¬ å¼€å§‹æ¶ˆèå®éªŒ...")
        logger.info(f"å®éªŒé…ç½®: {len(self.ablation_config['ablation_components'])}ä¸ªç»„ä»¶, "
                   f"{len(self.ablation_config['scenarios'])}ä¸ªåœºæ™¯, "
                   f"{len(self.ablation_config['agent_counts'])}ä¸ªä»£ç†æ•°é‡")
        
        ablation_results = []
        total_tests = (len(self.ablation_config['ablation_components']) * 
                      len(self.ablation_config['scenarios']) * 
                      len(self.ablation_config['agent_counts']) * 
                      len(self.ablation_config['complexities']) * 
                      self.ablation_config['repetitions'])
        
        current_test = 0
        
        for component in self.ablation_config['ablation_components']:
            for scenario in self.ablation_config['scenarios']:
                for agent_count in self.ablation_config['agent_counts']:
                    for complexity in self.ablation_config['complexities']:
                        for repetition in range(self.ablation_config['repetitions']):
                            current_test += 1
                            logger.info(f"ğŸ“Š æµ‹è¯•è¿›åº¦: {current_test}/{total_tests} - "
                                       f"{component} - {scenario} - {agent_count} agents - {complexity}")
                            
                            # è¿è¡Œæµ‹è¯•
                            result = self.test_dsl_component(component, scenario, agent_count, complexity)
                            
                            # æ·»åŠ é‡å¤æ¬¡æ•°ä¿¡æ¯
                            result["repetition"] = repetition + 1
                            ablation_results.append(result)
                            
                            # è®°å½•ç»“æœ
                            if result["status"] == "success":
                                logger.info(f"   âœ… æˆåŠŸ: ååé‡={result['throughput']:.3f} tasks/sec, "
                                           f"å»¶è¿Ÿ={result['avg_latency']:.2f} ms, "
                                           f"å†…å­˜={result['memory_usage']:.2f} MB")
                            else:
                                logger.error(f"   âŒ å¤±è´¥: {result.get('error', 'Unknown error')}")
                            
                            # çŸ­æš‚ä¼‘æ¯ä»¥é¿å…APIé™åˆ¶
                            time.sleep(1)
        
        # ä¿å­˜ç»“æœ
        results_file = "ablation_study_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump({
                "ablation_results": ablation_results,
                "memory_tracker": self.memory_tracker,
                "timestamp": datetime.now().isoformat(),
                "ablation_config": self.ablation_config,
                "test_info": {
                    "total_tests": len(ablation_results),
                    "components": self.ablation_config['ablation_components'],
                    "scenarios": self.ablation_config['scenarios'],
                    "agent_counts": self.ablation_config['agent_counts'],
                    "complexities": self.ablation_config['complexities'],
                    "repetitions": self.ablation_config['repetitions'],
                    "random_seed": self.random_seed
                }
            }, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… æ¶ˆèå®éªŒå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        # ç”Ÿæˆæ¶ˆèåˆ†æ
        self._generate_ablation_analysis(ablation_results)
        
        return {
            "ablation_results": ablation_results,
            "memory_tracker": self.memory_tracker,
            "timestamp": datetime.now().isoformat(),
            "ablation_config": self.ablation_config
        }
    
    def _generate_ablation_analysis(self, ablation_results: List[Dict[str, Any]]):
        """ç”Ÿæˆæ¶ˆèåˆ†æ"""
        logger.info("\nğŸ“Š æ¶ˆèå®éªŒåˆ†æ:")
        logger.info("=" * 60)
        
        # æŒ‰ç»„ä»¶åˆ†ç»„ç»Ÿè®¡
        component_stats = {}
        for result in ablation_results:
            if result["status"] == "success":
                component = result["component"]
                if component not in component_stats:
                    component_stats[component] = {
                        "throughput": [],
                        "latency": [],
                        "memory": [],
                        "success_rate": [],
                        "total_tests": 0,
                        "successful_tests": 0
                    }
                
                component_stats[component]["throughput"].append(result["throughput"])
                component_stats[component]["latency"].append(result["avg_latency"])
                component_stats[component]["memory"].append(result["memory_usage"])
                component_stats[component]["success_rate"].append(result["success_rate"])
                component_stats[component]["total_tests"] += 1
                if result["success_rate"] > 0:
                    component_stats[component]["successful_tests"] += 1
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        baseline_stats = component_stats.get("baseline", {})
        if baseline_stats and baseline_stats["throughput"]:
            baseline_throughput = np.mean(baseline_stats["throughput"])
            baseline_latency = np.mean(baseline_stats["latency"])
            baseline_memory = np.mean(baseline_stats["memory"])
            
            logger.info(f"\nåŸºçº¿ç‰ˆæœ¬ (å®Œæ•´åŠŸèƒ½):")
            logger.info(f"  å¹³å‡ååé‡: {baseline_throughput:.3f} tasks/sec")
            logger.info(f"  å¹³å‡å»¶è¿Ÿ: {baseline_latency:.2f} ms")
            logger.info(f"  å¹³å‡å†…å­˜ä½¿ç”¨: {baseline_memory:.2f} MB")
            
            # è®¡ç®—å„ç»„ä»¶çš„æ€§èƒ½å½±å“
            logger.info(f"\nç»„ä»¶æ€§èƒ½å½±å“åˆ†æ:")
            logger.info("-" * 40)
            
            for component, stats in component_stats.items():
                if component != "baseline" and stats["throughput"]:
                    avg_throughput = np.mean(stats["throughput"])
                    avg_latency = np.mean(stats["latency"])
                    avg_memory = np.mean(stats["memory"])
                    
                    throughput_change = ((avg_throughput - baseline_throughput) / baseline_throughput) * 100
                    latency_change = ((avg_latency - baseline_latency) / baseline_latency) * 100
                    memory_change = ((avg_memory - baseline_memory) / baseline_memory) * 100
                    
                    logger.info(f"\n{component}:")
                    logger.info(f"  ååé‡å˜åŒ–: {throughput_change:+.1f}% ({avg_throughput:.3f} tasks/sec)")
                    logger.info(f"  å»¶è¿Ÿå˜åŒ–: {latency_change:+.1f}% ({avg_latency:.2f} ms)")
                    logger.info(f"  å†…å­˜å˜åŒ–: {memory_change:+.1f}% ({avg_memory:.2f} MB)")
                    
                    # åˆ¤æ–­ç»„ä»¶é‡è¦æ€§
                    if abs(throughput_change) > 10:
                        importance = "é«˜"
                    elif abs(throughput_change) > 5:
                        importance = "ä¸­"
                    else:
                        importance = "ä½"
                    
                    logger.info(f"  ç»„ä»¶é‡è¦æ€§: {importance}")
        
        # æ€»ä½“ç»Ÿè®¡
        total_tests = len(ablation_results)
        successful_tests = sum(1 for r in ablation_results if r["status"] == "success")
        overall_success_rate = (successful_tests / total_tests) * 100
        
        logger.info(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        logger.info(f"  æˆåŠŸæµ‹è¯•: {successful_tests}")
        logger.info(f"  å¤±è´¥æµ‹è¯•: {total_tests - successful_tests}")
        logger.info(f"  æˆåŠŸç‡: {overall_success_rate:.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ æ¶ˆèå®éªŒæ¡†æ¶")
    print("=" * 50)
    print("âš ï¸  æ³¨æ„ï¼šæ­¤å®éªŒä½¿ç”¨çœŸå®APIè°ƒç”¨ï¼Œéœ€è¦æœ‰æ•ˆçš„APIå¯†é’¥")
    print("âš ï¸  å®éªŒè§„æ¨¡è¾ƒå¤§ï¼Œé¢„è®¡éœ€è¦è¾ƒé•¿æ—¶é—´å®Œæˆ")
    print("=" * 50)
    
    # åˆ›å»ºæ¶ˆèå®éªŒå®ä¾‹
    ablation = AblationStudy()
    
    # è¿è¡Œæ¶ˆèå®éªŒ
    results = ablation.run_ablation_study()
    
    print("\nğŸ‰ æ¶ˆèå®éªŒå®Œæˆï¼")
    print(f"æ€»æµ‹è¯•æ•°: {len(results['ablation_results'])}")
    print("ç»“æœå·²ä¿å­˜åˆ° ablation_study_results.json")

if __name__ == "__main__":
    main()
